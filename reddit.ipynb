{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d6f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a33c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import praw\n",
    "from datetime import datetime\n",
    "from psaw import PushshiftAPI\n",
    "import string\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01d59ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "up_ratio = 0.75  # min post upvote ratio\n",
    "post_ups = 20  # min # upvotes on post\n",
    "cmt_ups = 2  # min # upvotes on comment\n",
    "top_n_stocks = 5  # number of most mentioned stocks to consider\n",
    "posts_perday = 1000 # Number of posts to consider for each day\n",
    "\n",
    "# Modify these: Year, Month, Day\n",
    "start_date = int(datetime(2022,4,1).timestamp())\n",
    "end_date = int(datetime(2022,4,3).timestamp())\n",
    "\n",
    "r = praw.Reddit(\n",
    "    user_agent=\"sunflora\",\n",
    "    client_id=\"fQHJvnTwnElH2AOxXIt4nw\",\n",
    "    client_secret=\"UW3GeW8iCJCHbly-hYqd7Cgscx72Jw\"\n",
    ")\n",
    "reddit = PushshiftAPI(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f93983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock data adapted from https://github.com/jklepatch/eattheblocks/blob/master/screencast/290-wallstreetbets-sentiment-analysis/data.py\n",
    "# csv file from https://www.nasdaq.com/market-activity/stocks/screener?exchange=nasdaq&letter=0&render=download\\\n",
    "\n",
    "stock_screener = pd.read_csv(\"nasdaq_screener_1649302163756.csv\")\n",
    "stocks = []\n",
    "for i in range(stock_screener.shape[0]):\n",
    "    stocks.append(stock_screener['Symbol'][i])\n",
    "\n",
    "# blacklist words that might be confused as stock names\n",
    "blacklist = {'I', 'ELON', 'WSB', 'THE', 'A', 'ROPE', 'YOLO', 'TOS', 'CEO', 'DD', 'IT', 'OPEN', 'ATH', 'PM', 'IRS', 'FOR','DEC', 'BE', 'IMO', 'ALL', 'RH', 'EV', 'TOS', 'CFO', 'CTO', 'DD', 'BTFD', 'WSB', 'OK', 'PDT', 'RH', 'KYS', 'FD', 'TYS', 'US', 'USA', 'IT', 'ATH', 'RIP', 'BMW', 'GDP', 'OTM', 'ATM', 'ITM', 'IMO', 'LOL', 'AM', 'BE', 'PR', 'PRAY', 'PT', 'FBI', 'SEC', 'GOD', 'NOT', 'POS', 'FOMO', 'TL;DR', 'EDIT', 'STILL', 'WTF', 'RAW', 'PM', 'LMAO', 'LMFAO', 'ROFL', 'EZ', 'RED', 'BEZOS', 'TICK', 'IS', 'PM', 'LPT', 'GOAT', 'FL', 'CA', 'IL', 'MACD', 'HQ', 'OP', 'PS', 'AH', 'TL', 'JAN', 'FEB', 'JUL', 'AUG', 'SEP', 'SEPT', 'OCT', 'NOV', 'FDA', 'IV', 'ER', 'IPO', 'MILF', 'BUT', 'SSN', 'FIFA', 'USD', 'CPU', 'AT', 'GG', 'Mar','ARE','GO',\n",
    "             'ON','J','VERY','REAL','FAST','ANY','GET','UK','HAS','CAN','IQ'}\n",
    "\n",
    "# adding words to update the dictionary of SentimentIntensityAnalyzer() based on reddit\n",
    "new_words = {\n",
    "    'citron': -4.0,\n",
    "    'hidenburg': -4.0,\n",
    "    'moon': 4.0,\n",
    "    'highs': 2.0,\n",
    "    'mooning': 4.0,\n",
    "    'long': 2.0,\n",
    "    'short': -2.0,\n",
    "    'call': 4.0,\n",
    "    'calls': 4.0,\n",
    "    'put': -4.0,\n",
    "    'puts': -4.0,\n",
    "    'break': 2.0,\n",
    "    'tendie': 2.0,\n",
    "     'tendies': 2.0,\n",
    "     'town': 2.0,\n",
    "     'overvalued': -3.0,\n",
    "     'undervalued': 3.0,\n",
    "     'buy': 4.0,\n",
    "     'sell': -4.0,\n",
    "     'gone': -1.0,\n",
    "     'gtfo': -1.7,\n",
    "     'paper': -1.7,\n",
    "     'bullish': 3.7,\n",
    "     'bearish': -3.7,\n",
    "     'bagholder': -1.7,\n",
    "     'stonk': 1.9,\n",
    "     'green': 1.9,\n",
    "     'money': 1.2,\n",
    "     'print': 2.2,\n",
    "     'rocket': 2.2,\n",
    "     'bull': 2.9,\n",
    "     'bear': -2.9,\n",
    "     'pumping': -1.0,\n",
    "     'sus': -3.0,\n",
    "     'offering': -2.3,\n",
    "     'rip': -4.0,\n",
    "     'downgrade': -3.0,\n",
    "     'upgrade': 3.0,\n",
    "     'maintain': 1.0,\n",
    "     'pump': 1.9,\n",
    "     'hot': 1.5,\n",
    "     'drop': -2.5,\n",
    "     'rebound': 1.5,\n",
    "     'crack': 2.5,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11a128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up comments\n",
    "def clean(cmt_string):\n",
    "    punctuations = cmt_string.translate(str.maketrans('', '', string.punctuation))  # get rid of punctuations\n",
    "    return punctuations\n",
    "\n",
    "\n",
    "# limit = number of posts\n",
    "def get_posts(start_date, end_date, limit):\n",
    "    # We set by default some useful columns\n",
    "    posts = list(reddit.search_submissions(\n",
    "        subreddit='wallstreetbets',\n",
    "        after=start_date,\n",
    "        before=end_date,\n",
    "        limit=limit\n",
    "    ))\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e8cec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_picks(start, end, limit):\n",
    "    \"\"\"\n",
    "    :param start: Starting epoch\n",
    "    :param end: Ending epoch\n",
    "    :param limit: Number of posts to retrieve\n",
    "    :return: dictionary: {top n_stocks: list of comments about that stock}\n",
    "    \"\"\"\n",
    "\n",
    "    cmt_list = []  # stores all text\n",
    "    relevant_comments = []\n",
    "    stock_count = {}  # stores stock_name:count\n",
    "    stock_cmts = {}  # stores stock_name: [comments]\n",
    "    pick_cmts = {}  # stock_cmts for top n stocks\n",
    "    \n",
    "    posts = get_posts(start, end, limit)  # retrieve posts\n",
    "    \n",
    "    for submission in posts:\n",
    "        if submission.score > post_ups:\n",
    "            cmt_list.append(clean(submission.title))\n",
    "\n",
    "            if submission.selftext != \"\":\n",
    "                cmt_list.append(clean(submission.selftext))\n",
    "\n",
    "            submission.comments.replace_more(limit=10)  # Number of more_comment objects to replace\n",
    "            for comment in submission.comments.list():  # get comments + replies\n",
    "                if comment.score > cmt_ups:\n",
    "                    cmt_list.append(clean(comment.body))\n",
    "\n",
    "\n",
    "    for cmt in cmt_list:\n",
    "        word_list = cmt.split()\n",
    "        for word in word_list:\n",
    "            if word.isupper() and word in stocks and word not in blacklist:\n",
    "                relevant_comments.append(cmt)\n",
    "\n",
    "                if word not in stock_count:\n",
    "                    stock_count[word] = 1\n",
    "                    stock_cmts[word] = [cmt]\n",
    "\n",
    "                else:\n",
    "                    stock_count[word] += 1\n",
    "                    stock_cmts[word].append(cmt)\n",
    "\n",
    "    sorted_stock_count = dict(sorted(stock_count.items(), key=lambda item: item[1], reverse=True))\n",
    "    picks = list(sorted_stock_count.keys())[0:top_n_stocks]\n",
    "\n",
    "    for st in picks:\n",
    "        pick_cmts[st] = stock_cmts[st]\n",
    "\n",
    "    return pick_cmts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a3d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(comment_dict):\n",
    "    \"\"\"\n",
    "    :param comment_dict: dictionary of {stock_name: [list of stock comments]}\n",
    "    :return: dictionary of {stock_name: dictionary of {sentiment:score}}\n",
    "    \"\"\"\n",
    "    \n",
    "    jack = SentimentIntensityAnalyzer()\n",
    "    jack.lexicon.update(new_words)\n",
    "\n",
    "    top_picks = list(comment_dict.keys())\n",
    "    score_dict = dict.fromkeys(top_picks)\n",
    "    for x in score_dict:  # stock = x\n",
    "        x_comments = comment_dict[x]  # all relevant comments of stock x\n",
    "        score_dict[x] = {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound': 0.0}\n",
    "        for c in x_comments:\n",
    "            sentiment_dict = jack.polarity_scores(c)\n",
    "            for key in sentiment_dict.keys():\n",
    "                score_dict[x][key] += sentiment_dict[key]\n",
    "\n",
    "        # need to average each entry in score_dict\n",
    "        for k in score_dict[x]:\n",
    "            score_dict[x][k] = score_dict[x][k]/len(x_comments)\n",
    "\n",
    "    return score_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad14b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [] # List of data frames generated\n",
    "df_commentDicts = {} # Date : comment_dictionary\n",
    "\n",
    "starting_time = time.time()\n",
    "for i in range(int(start_date), int(end_date)+86400,86400):\n",
    "    curr_date = datetime.fromtimestamp(i).strftime('%Y-%m-%d')\n",
    "    print(f'Now working on posts from {curr_date}...')\n",
    "    comment_dictionary = get_picks(i, i+86400, posts_perday)\n",
    "    df = pd.DataFrame(sentiment_score(comment_dictionary))\n",
    "    df.index = ['Bearish', 'Neutral', 'Bullish', 'Total_Compound']\n",
    "    df = df.T\n",
    "    df.index.name = 'stock'\n",
    "    dates = [i for x in range(top_n_stocks)]\n",
    "    df['Date'] = dates\n",
    "    df_list.append(df)\n",
    "    df_commentDicts[i] = comment_dictionary\n",
    "    diff = time.time() - starting_time\n",
    "    print(f'{curr_date} completed in {diff} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3735d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(df_list,axis=0) # Concatenate all the dataframes for each day\n",
    "final_df = final_df.reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df405ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe as a csv file\n",
    "x = datetime.fromtimestamp(start_date).strftime('%Y-%m-%d')\n",
    "y = datetime.fromtimestamp(end_date).strftime('%Y-%m-%d')\n",
    "final_df.to_csv(f'{x}-{y}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c376b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
